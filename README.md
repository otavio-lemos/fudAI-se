# fudAI-se

# Solu√ß√µes de IA - Conceitos, Ferramentas e Recursos

<div align="center">

<!-- Modelos de IA -->
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-412991?logo=openai&logoColor=white)](https://openai.com)
[![Anthropic](https://img.shields.io/badge/Anthropic-Claude_3.5-D97757?logo=anthropic&logoColor=white)](https://anthropic.com)
[![Google DeepMind](https://img.shields.io/badge/Google-Gemini_1.5-4285F4?logo=google&logoColor=white)](https://deepmind.google/technologies/gemini/)
[![Meta](https://img.shields.io/badge/Meta-Llama_3-0668E1?logo=meta&logoColor=white)](https://ai.meta.com/llama/)
[![Mistral](https://img.shields.io/badge/Mistral-AI-F5A623?logo=mistral&logoColor=white)](https://mistral.ai)
[![Hugging Face](https://img.shields.io/badge/Hugging_Face-Hub-FFD21E?logo=huggingface&logoColor=black)](https://huggingface.co)
[![DeepSeek](https://img.shields.io/badge/DeepSeek-V3-000000?logo=deepseek&logoColor=white)](https://www.deepseek.com/)
[![Alibaba Cloud](https://img.shields.io/badge/Alibaba-Qwen_2.5-FF6A00?logo=alibabacloud&logoColor=white)](https://www.alibabacloud.com/)

<!-- Gera√ß√£o de Imagem, √Åudio e V√≠deo -->
[![Stability AI](https://img.shields.io/badge/Stability_AI-Stable_Diffusion-000000?logo=stabilityai&logoColor=white)](https://stability.ai/)
[![Midjourney](https://img.shields.io/badge/Midjourney-Art-FFFFFF?logo=midjourney&logoColor=black)](https://www.midjourney.com/)
[![ElevenLabs](https://img.shields.io/badge/ElevenLabs-Voice_AI-000000?logo=elevenlabs&logoColor=white)](https://elevenlabs.io/)
[![Suno](https://img.shields.io/badge/Suno-Bark-000000?logo=suno&logoColor=white)](https://suno.ai/)

<!-- Frameworks & Orquestra√ß√£o -->
[![LangChain](https://img.shields.io/badge/LangChain-Orchestration-1C3C3C?logo=langchain&logoColor=white)](https://langchain.com)
[![LlamaIndex](https://img.shields.io/badge/LlamaIndex-Data_Framework-121212?logo=llamaindex&logoColor=white)](https://www.llamaindex.ai/)
[![Microsoft](https://img.shields.io/badge/Microsoft-Semantic_Kernel-0078D4?logo=microsoft&logoColor=white)](https://github.com/microsoft/semantic-kernel)
[![AutoGen](https://img.shields.io/badge/Microsoft-AutoGen-0078D4?logo=microsoft&logoColor=white)](https://microsoft.github.io/autogen/)
[![DSPy](https://img.shields.io/badge/Stanford-DSPy-8C1515?logo=stanford&logoColor=white)](https://github.com/stanfordnlp/dspy)
[![LangGraph](https://img.shields.io/badge/LangGraph-Agents-1C3C3C?logo=langchain&logoColor=white)](https://langchain.com/langgraph)

<!-- Frontend & Backend -->
[![Streamlit](https://img.shields.io/badge/Streamlit-Frontend-FF4B4B?logo=streamlit&logoColor=white)](https://streamlit.io)
[![FastAPI](https://img.shields.io/badge/FastAPI-Backend-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![Gradio](https://img.shields.io/badge/Gradio-Demos-FF7C00?logo=gradio&logoColor=white)](https://gradio.app/)
[![Chainlit](https://img.shields.io/badge/Chainlit-UI-000000?logo=chainlit&logoColor=white)](https://chainlit.io/)

<!-- Deep Learning & Dados -->
[![PyTorch](https://img.shields.io/badge/PyTorch-Deep_Learning-EE4C2C?logo=pytorch&logoColor=white)](https://pytorch.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-ML-FF6F00?logo=tensorflow&logoColor=white)](https://www.tensorflow.org)
[![Scikit-learn](https://img.shields.io/badge/scikit--learn-ML-F7931E?logo=scikitlearn&logoColor=white)](https://scikit-learn.org/)
[![Pandas](https://img.shields.io/badge/Pandas-Data_Analysis-150458?logo=pandas&logoColor=white)](https://pandas.pydata.org/)
[![NumPy](https://img.shields.io/badge/NumPy-Math-013243?logo=numpy&logoColor=white)](https://numpy.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-Computer_Vision-5C3EE8?logo=opencv&logoColor=white)](https://opencv.org/)
[![spaCy](https://img.shields.io/badge/spaCy-NLP-09A3D5?logo=spacy&logoColor=white)](https://spacy.io/)
[![JAX](https://img.shields.io/badge/Google-JAX-4285F4?logo=google&logoColor=white)](https://jax.readthedocs.io/)

<!-- Bancos de Dados -->
[![Pinecone](https://img.shields.io/badge/Pinecone-Vector_DB-000000?logo=pinecone&logoColor=white)](https://www.pinecone.io)
[![Weaviate](https://img.shields.io/badge/Weaviate-Vector_DB-FA0171?logo=weaviate&logoColor=white)](https://weaviate.io)
[![Qdrant](https://img.shields.io/badge/Qdrant-Vector_DB-9D16F3?logo=qdrant&logoColor=white)](https://qdrant.tech)
[![Milvus](https://img.shields.io/badge/Milvus-Vector_DB-00A1EA?logo=milvus&logoColor=white)](https://milvus.io)
[![Neo4j](https://img.shields.io/badge/Neo4j-Graph_DB-008CC1?logo=neo4j&logoColor=white)](https://neo4j.com)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-pgvector-336791?logo=postgresql&logoColor=white)](https://www.postgresql.org/)

<!-- Infraestrutura & Cloud -->
[![Docker](https://img.shields.io/badge/Docker-Containers-2496ED?logo=docker&logoColor=white)](https://www.docker.com/)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Orchestration-326CE5?logo=kubernetes&logoColor=white)](https://kubernetes.io/)
[![Ray](https://img.shields.io/badge/Ray-Distributed_Compute-028CF0?logo=ray&logoColor=white)](https://www.ray.io/)
[![Google Cloud](https://img.shields.io/badge/Google_Cloud-Vertex_AI-4285F4?logo=googlecloud&logoColor=white)](https://cloud.google.com/vertex-ai)
[![AWS](https://img.shields.io/badge/AWS-SageMaker-232F3E?logo=amazonwebservices&logoColor=white)](https://aws.amazon.com/sagemaker/)
[![Azure](https://img.shields.io/badge/Azure-Machine_Learning-0078D4?logo=microsoftazure&logoColor=white)](https://azure.microsoft.com/en-us/products/machine-learning/)
[![Groq](https://img.shields.io/badge/Groq-LPU_Inference-F55036?logo=groq&logoColor=white)](https://groq.com/)
[![RunPod](https://img.shields.io/badge/RunPod-GPU_Cloud-6B46C1?logo=runpod&logoColor=white)](https://runpod.io/)
[![Modal](https://img.shields.io/badge/Modal-Serverless_GPU-000000?logo=modal&logoColor=white)](https://modal.com/)
[![Vercel](https://img.shields.io/badge/Vercel-Deployment-000000?logo=vercel&logoColor=white)](https://vercel.com/)

<!-- Observabilidade & Monitoramento -->
[![Datadog](https://img.shields.io/badge/Datadog-Monitoring-632CA6?logo=datadog&logoColor=white)](https://www.datadoghq.com/)
[![Helicone](https://img.shields.io/badge/Helicone-Observability-000000?logo=helicone&logoColor=white)](https://www.helicone.ai/)
[![LangSmith](https://img.shields.io/badge/LangSmith-Tracing-1C3C3C?logo=langchain&logoColor=white)](https://smith.langchain.com/)
[![Langfuse](https://img.shields.io/badge/Langfuse-Observability-000000?logo=langfuse&logoColor=white)](https://langfuse.com/)
[![Weights & Biases](https://img.shields.io/badge/Weights_&_Biases-Experiment_Tracking-FFBE00?logo=weightsandbiases&logoColor=black)](https://wandb.ai/)
[![MLflow](https://img.shields.io/badge/MLflow-Lifecycle-0194E2?logo=mlflow&logoColor=white)](https://mlflow.org/)

<!-- Ferramentas, Busca & Automa√ß√£o -->
[![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?logo=python&logoColor=white)](https://www.python.org/)
[![Mermaid](https://img.shields.io/badge/Mermaid-Diagrams-FF3570?logo=mermaid&logoColor=white)](https://mermaid.js.org)
[![Unsloth](https://img.shields.io/badge/Unsloth-Fine--tuning-000000?logo=github&logoColor=white)](https://github.com/unslothai/unsloth)
[![Axolotl](https://img.shields.io/badge/Axolotl-Fine--tuning-000000?logo=github&logoColor=white)](https://github.com/OpenAccess-AI-Collective/axolotl)
[![Perplexity](https://img.shields.io/badge/Perplexity-Search_API-222222?logo=perplexity&logoColor=white)](https://www.perplexity.ai/)
[![MCP](https://img.shields.io/badge/MCP-Model_Context_Protocol-000000?logo=json&logoColor=white)](https://modelcontextprotocol.io/)
[![Tavily](https://img.shields.io/badge/Tavily-AI_Search-000000?logo=google&logoColor=white)](https://tavily.com/)
[![Dify](https://img.shields.io/badge/Dify-No--Code_LLM-000000?logo=dify&logoColor=white)](https://dify.ai/)
[![Ollama](https://img.shields.io/badge/Ollama-Local_LLMs-000000?logo=ollama&logoColor=white)](https://ollama.com/)
[![Cursor](https://img.shields.io/badge/Cursor-AI_Editor-000000?logo=cursor&logoColor=white)](https://cursor.sh/)
[![GitHub Copilot](https://img.shields.io/badge/GitHub_Copilot-AI_Coding-FFFFFF?logo=githubcopilot&logoColor=black)](https://github.com/features/copilot)
[![Make](https://img.shields.io/badge/Make-Automation-000000?logo=make&logoColor=white)](https://www.make.com/)
[![n8n](https://img.shields.io/badge/n8n-Workflow-FF6584?logo=n8n&logoColor=white)](https://n8n.io/)
[![Zapier](https://img.shields.io/badge/Zapier-Integration-FF4F00?logo=zapier&logoColor=white)](https://zapier.com/)

</div>

</div>

---

## 1. Conceitos Fundamentais de IA

### 1.1 Arquiteturas e Tipos de Modelos

| Conceito               | Defini√ß√£o                                                   | Caracter√≠sticas                                                   |
| :--------------------- | :---------------------------------------------------------- | :--------------------------------------------------------------- |
| **LLM**                | Modelo neural treinado em bilh√µes de tokens de texto        | Par√¢metros: 7B-405B; Entende contexto; Suporta m√∫ltiplos idiomas  |
| **SLM**                | Vers√£o compacta de LLM (1B-8B par√¢metros)                   | Tamanho: 1GB-8GB; Lat√™ncia <100ms; Roda offline                  |
| **VLM**                | Modelo que processa texto, imagens e v√≠deos                 | Processa m√∫ltiplas modalidades; Descreve cenas complexas         |
| **MoE**                | Arquitetura com diferentes "especialistas"                  | Escalabilidade; Efici√™ncia; Mixtral 8x7B                         |
| **Text-to-Image**      | Modelo que cria imagens a partir de texto                   | Gera√ß√£o em tempo real; M√∫ltiplos estilos; Alta resolu√ß√£o         |
| **Image-to-Text**      | Modelo que descreve imagens em linguagem natural            | Descri√ß√£o detalhada; Extra√ß√£o de texto em imagens                |
| **Multimodal Learning** | Modelos que processam m√∫ltiplas modalidades simultaneamente | Integra√ß√£o de modalidades; Contexto rico                         |

### 1.2 T√©cnicas e M√©todos (RAG & Training)

| Conceito | Defini√ß√£o | Caracter√≠sticas |
|----------|-----------|----------------|
| **RAG** | Conecta LLM a base de conhecimento externa | Busca documentos; Aumenta precis√£o; Reduz alucina√ß√µes |
| **Agentic RAG** | Agente decide autonomamente quando buscar | Planejamento inteligente; M√∫ltiplas buscas coordenadas |
| **GraphRAG** | Combina knowledge graphs com busca vetorial | Mapeia relacionamentos; An√°lise de redes |
| **Fine-tuning** | Treinar modelo com dados espec√≠ficos do dom√≠nio | Adapta modelo gen√©rico; Melhora precis√£o |
| **LoRA** | Fine-tuning eficiente com matrizes de baixa dimensionalidade | Reduz par√¢metros em 99%; Treinamento 10x mais r√°pido |
| **Quantization** | Reduz precis√£o num√©rica do modelo | Reduz tamanho em 75%; Aumenta velocidade em 4x |
| **RLHF** | Alinha modelo com prefer√™ncias humanas | Melhora qualidade; Reduz respostas indesejadas |
| **Transfer Learning** | Usa conhecimento de um modelo treinado | Reutiliza√ß√£o de conhecimento; Reduz tempo de treinamento |
| **Tool Use / Function Calling** | Modelo chama fun√ß√µes externas | Integra√ß√£o com sistemas; Acesso a dados em tempo real |

### 1.3 Engenharia de Prompts e Infer√™ncia

| Conceito | Defini√ß√£o | Caracter√≠sticas |
|----------|-----------|----------------|
| **Prompt Engineering** | Formular prompts eficazes | Estrutura clara; Few-shot; Instru√ß√µes expl√≠citas |
| **Chain-of-Thought (CoT)** | Modelo mostra racioc√≠nio passo a passo | Melhora acur√°cia; Racioc√≠nio transparente |
| **Few-Shot Learning** | Fornecer poucos exemplos no prompt | 2-5 exemplos; Sem treinamento adicional |
| **Zero-Shot Learning** | Executar tarefa sem exemplos | Generaliza√ß√£o; Flexibilidade |
| **Temperature** | Controla criatividade vs. determinismo | 0 = determin√≠stico; 1 = criativo |
| **Top-K e Top-P Sampling** | Controle de diversidade nas respostas | Top-K: K tokens mais prov√°veis; Top-P: at√© probabilidade P |
| **Speculative Decoding** | Modelo pequeno "rascunha" tokens verificados por maior | Aumenta velocidade 2-3x; Mant√©m qualidade |

### 1.4 Infraestrutura e M√©tricas

| Conceito | Defini√ß√£o | Caracter√≠sticas |
|----------|-----------|----------------|
| **Token** | Unidade b√°sica de processamento em LLMs | ~4 caracteres = 1 token; Contagem determina custo |
| **Context Window** | Quantidade m√°xima de tokens que modelo processa | Varia de 4K a 200K tokens |
| **TTFT** | Tempo entre envio do prompt e primeiro token | Cr√≠tico para UX; Menor √© melhor |
| **TPS** | Tokens gerados por segundo | >50 TPS ideal para leitura humana |
| **KV Cache** | Armazena c√°lculos de aten√ß√£o passados | Reduz computa√ß√£o repetitiva; Aumenta velocidade |
| **Batch Processing** | Processar grandes volumes com pre√ßo reduzido | Economia de 50-80%; Ideal para volumes altos |
| **Streaming** | Processamento em tempo real | Lat√™ncia <1s; Ideal para chatbots |
| **Hallucination** | Modelo gera informa√ß√µes incorretas | Reduzido com RAG; Mitigado com fact-checking |

### 1.5 Dom√≠nios e Busca

| Conceito | Defini√ß√£o | Caracter√≠sticas |
|----------|-----------|----------------|
| **NLP** | Compreens√£o e gera√ß√£o de linguagem natural | An√°lise de sentimento; Extra√ß√£o de entidades; Tradu√ß√£o |
| **Computer Vision** | An√°lise e compreens√£o de imagens e v√≠deos | Detec√ß√£o de objetos; Segmenta√ß√£o; Reconhecimento facial |
| **OCR** | Extrai texto de imagens ou documentos | Reconhecimento de caracteres; Preserva√ß√£o de layout |
| **ASR** | Converte √°udio falado em texto | Reconhecimento de fala; Suporte multil√≠ngue |
| **TTS** | Converte texto em √°udio falado | S√≠ntese de voz natural; M√∫ltiplas vozes |
| **Embeddings** | Representa√ß√£o num√©rica que captura significado | Dimensionalidade: 384-1536; Busca sem√¢ntica |
| **Vector Search** | Busca por similaridade em espa√ßo vetorial | Busca por significado; R√°pida em grandes volumes |
| **Semantic Search** | Busca que entende significado | Busca por conceito; Resultados mais relevantes |
| **Knowledge Graph** | Representa√ß√£o estruturada de conhecimento | Mapeia relacionamentos; Racioc√≠nio l√≥gico |
| **Retrieval Ranking** | Reordena resultados de busca | Melhora precis√£o em 20-40%; Usa cross-encoders |
| **Query Rewriting** | Reformula queries do usu√°rio | Expande queries; Melhora relev√¢ncia |

---

## 2. Ferramentas e Frameworks

### 2.1 Frameworks

| Framework | O que faz | Quando usar |
|-----------|-----------|-------------|
| **LangChain** | Simplifica constru√ß√£o de aplica√ß√µes com LLMs | Qualquer aplica√ß√£o com LLM; RAG; Chains; Agents |
| **LangGraph** | Construir agentes com controle via state machines | Agentes complexos; Workflows m√∫ltiplas etapas |
| **DSPy** | Otimizar prompts programaticamente | Pipelines complexos; Otimiza√ß√£o autom√°tica |
| **AutoGen** | Multi-agent systems onde agentes conversam | Sistemas multi-agente; Colabora√ß√£o entre agentes |
| **LlamaIndex** | Construir aplica√ß√µes RAG com indexa√ß√£o inteligente | RAG; Indexa√ß√£o de documentos; Busca sem√¢ntica |
| **Streamlit** | Criar aplica√ß√µes web interativas com Python | Prototipagem r√°pida; Dashboards; Demos |
| **Gradio** | Criar interfaces web para modelos de ML | Demos de modelos; Interfaces simples |
| **FastAPI** | Construir APIs r√°pidas e eficientes | APIs de produ√ß√£o; Microservi√ßos |
| **TensorFlow** | Framework de deep learning do Google | Deep learning; Pesquisa; Produ√ß√£o |
| **PyTorch** | Framework de deep learning do Meta | Pesquisa; Prototipagem; Flexibilidade |
| **JAX** | Computa√ß√£o num√©rica com diferencia√ß√£o autom√°tica | Pesquisa avan√ßada; Computa√ß√£o de alto desempenho |

---

### 2.2 Bibliotecas

| Biblioteca | O que faz | Quando usar |
|------------|-----------|-------------|
| **Hugging Face Transformers** | Acesso a milhares de modelos pr√©-treinados | Fine-tuning; Uso de modelos open-source |
| **spaCy** | NLP otimizada para produ√ß√£o | Processamento de texto; Extra√ß√£o de entidades |
| **OpenCV** | Vis√£o computacional | Processamento de imagem; Manipula√ß√£o de v√≠deo |
| **Scikit-learn** | ML cl√°ssico com algoritmos tradicionais | Classifica√ß√£o; Regress√£o; Clustering |
| **Pandas** | Manipula√ß√£o e an√°lise de dados estruturados | Processamento de dados; An√°lise |
| **NumPy** | Computa√ß√£o num√©rica e opera√ß√µes em arrays | C√°lculos num√©ricos; Opera√ß√µes matriciais |
| **Matplotlib / Seaborn** | Visualiza√ß√£o de dados e gr√°ficos | Visualiza√ß√£o; An√°lise explorat√≥ria |
| **Plotly** | Visualiza√ß√µes interativas e dashboards | Dashboards interativos; Visualiza√ß√µes web |

---

### 2.3 Engines

| Engine | O que faz | Quando usar |
|--------|-----------|-------------|
| **YOLO** | Detec√ß√£o de objetos em tempo real | Detec√ß√£o de objetos; Vigil√¢ncia; An√°lise de v√≠deo |
| **Detectron2** | Detec√ß√£o e segmenta√ß√£o de objetos avan√ßada | Segmenta√ß√£o de inst√¢ncias; Detec√ß√£o complexa |
| **Tesseract** | OCR open-source com 100+ idiomas | Extra√ß√£o de texto de imagens; Documentos escaneados |
| **vLLM** | Serving de LLMs com alta throughput | Serving de modelos; Alta performance |
| **TGI** | Serving de LLMs em produ√ß√£o | Serving de modelos; Otimizado para produ√ß√£o |

---

### 2.4 Plataformas

| Plataforma | O que faz | Quando usar |
|-----------|-----------|-------------|
| **Dify** | Construir aplica√ß√µes de IA sem c√≥digo | N√£o-t√©cnicos; Prototipagem r√°pida; Chatbots |
| **Ollama** | Rodar modelos LLM localmente | Modelos offline; Privacidade; Desenvolvimento local |
| **LangSmith** | Rastrear, debugar e monitorar aplica√ß√µes LLM | Debugging; Observabilidade; Otimiza√ß√£o de prompts |
| **Langfuse** | Observabilidade open-source para LLMs | Rastreamento; Analytics; Debugging |
| **Weights & Biases** | Rastreamento de experimentos de ML | Treinamento de modelos; Experimentos |
| **MLflow** | Gerenciar ciclo de vida de ML | Versionamento de modelos; Rastreamento; Deployment |
| **Prompt Flow** | Construir e testar workflows com LLMs | Desenvolvimento de prompts; Workflows; Testes |
| **Semantic Kernel** | Integrar LLMs em aplica√ß√µes .NET | Integra√ß√£o com C#/.NET; Plugins; Orquestra√ß√£o |

---

### 2.5 Frameworks de Fine-tuning

| Framework | Tipo | O que faz | Quando usar |
|-----------|------|-----------|-------------|
| **Transformers Trainer** | Open-source | Fine-tuning de modelos Hugging Face | Fine-tuning de LLMs; Mais utilizado |
| **Axolotl** | Open-source | Fine-tuning com configura√ß√£o YAML | Fine-tuning r√°pido; Configura√ß√£o simples |
| **TRL** | Open-source | RLHF e fine-tuning com refor√ßo | Fine-tuning com feedback humano |
| **Unsloth** | Open-source | Fine-tuning r√°pido e eficiente | Fine-tuning 2-5x mais r√°pido; Economia de mem√≥ria |
| **Torchtune** | Open-source | Fine-tuning de modelos Llama | Fine-tuning de Llama; Otimizado |

---

### 2.6 Orquestradores

| Orquestrador | O que faz | Quando usar |
|--------------|-----------|-------------|
| **Kubernetes** | Orquestra√ß√£o de containers em escala | Deployment em escala; Alta disponibilidade |
| **Airflow** | Orquestra√ß√£o de workflows de dados complexos | Pipelines de dados; Agendamento |
| **Prefect** | Orquestra√ß√£o de workflows moderna | Pipelines de dados; Workflows complexos |

---

### 2.7 Plataformas No-Code / Low-Code

| Plataforma | O que faz | Quando usar |
|------------|-----------|-------------|
| **Dify** | Construir aplica√ß√µes de IA sem c√≥digo | N√£o-t√©cnicos; Prototipagem r√°pida |
| **Make** | Automa√ß√£o de workflows sem c√≥digo | Integra√ß√£o de sistemas; Automa√ß√£o de processos |
| **Zapier** | Automa√ß√£o e integra√ß√£o de aplica√ß√µes | Conectar apps; Automa√ß√£o de tarefas |
| **n8n** | Automa√ß√£o open-source de workflows | Open-source; Automa√ß√£o complexa; Self-hosted |
| **Bubble** | Construir aplica√ß√µes web sem c√≥digo | Aplica√ß√µes web completas; Prototipagem r√°pida |
| **FlutterFlow** | Construir apps mobile sem c√≥digo | Apps mobile; UI/UX visual |

---

### 2.8 Plataformas Vibecoding

| Plataforma | O que faz | Quando usar |
|------------|-----------|-------------|
| **Cursor** | IDE com IA integrada | Desenvolvimento r√°pido; Pair programming com IA |
| **GitHub Copilot** | Autocompletar de c√≥digo com IA | Desenvolvimento; Sugest√µes de c√≥digo |
| **Windsurf** | IDE com IA para desenvolvimento assistido | Desenvolvimento r√°pido; Alternativa a Cursor |
| **Cline** | Agente de IA para desenvolvimento | Desenvolvimento aut√¥nomo; Cria√ß√£o de projetos |
| **Claude for VSCode** | Extens√£o Claude no VSCode | Desenvolvimento com Claude; Integra√ß√£o VSCode |
| **Aider** | CLI para desenvolvimento assistido por IA | Desenvolvimento via terminal; Pair programming |

---

### 2.9 Plataformas de Deployment

| Plataforma | O que faz | Quando usar |
|------------|-----------|-------------|
| **Docker** | Containeriza√ß√£o de aplica√ß√µes | Deployment; Escalabilidade; Reprodutibilidade |
| **Ray** | Processamento paralelo e ML em escala | Processamento paralelo; Treinamento distribu√≠do |
| **Vertex AI** | Plataforma Google para ML | ML end-to-end; AutoML; Modelos Google |
| **SageMaker** | Plataforma AWS para ML | ML end-to-end; Treinamento; Deployment |
| **Azure ML** | Plataforma Microsoft para ML | ML end-to-end; Integra√ß√£o Azure |
| **Modal** | Platform serverless para rodar c√≥digo Python em GPU | Deployment r√°pido; Escal√°vel |
| **RunPod** | Plataforma para rodar workloads em GPU | GPU acess√≠vel; Treinamento; Inference |

---

### 2.10 Ferramentas de Avalia√ß√£o e Testing

| Ferramenta | O que faz | Quando usar |
|------------|-----------|-------------|
| **RAGAS** | Avaliar qualidade de sistemas RAG | Avaliar RAG; M√©tricas de relev√¢ncia |
| **DeepEval** | Avaliar qualidade de LLMs | Testes de LLM; M√©tricas customizadas |
| **Braintrust** | Avaliar e comparar LLMs | Compara√ß√£o de modelos; A/B testing |

---

### 2.11 Ferramentas de Processamento de Dados

| Ferramenta | O que faz | Quando usar |
|------------|-----------|-------------|
| **Airbyte** | ETL/ELT open-source | Integra√ß√£o de dados; Pipelines de dados |
| **dbt** | Transforma√ß√£o de dados em data warehouses | Transforma√ß√£o de dados; Data modeling |
| **Label Studio** | Data labeling open-source | Criar datasets; Anota√ß√£o de dados; Fine-tuning |

---

### 2.12 Ferramentas de Monitoramento de Custos

| Ferramenta | O que faz | Quando usar |
|------------|-----------|-------------|
| **Helicone** | Rastrear gastos com APIs de LLM | Monitoramento de custos; Analytics |
| **Lithic** | Monitoramento de uso de APIs | Rastreamento de uso; Alertas; An√°lise de custos |

---

## 3. Recursos, Servi√ßos e APIs

### 3.1 Modelos LLM (Open-source)

| Modelo | Provedor | Caracter√≠sticas |
|--------|----------|----------------|
| **Llama 3.2, 3.1, 2** | Meta | Open-source; 1B-405B par√¢metros; Roda localmente |
| **Mistral 7B, Mixtral 8x7B** | Mistral AI | Open-source; Eficiente; Excelente custo-benef√≠cio |
| **Qwen 2.5** | Alibaba | Open-source; M√∫ltiplos tamanhos; Muito utilizado na √Åsia |
| **DeepSeek-V3** | DeepSeek | Open-source; Excelente racioc√≠nio; Custo-benef√≠cio superior |

---

### 3.2 Modelos LLM (Propriet√°rios)

| Modelo | Provedor | Caracter√≠sticas |
|--------|----------|----------------|
| **GPT-4o, GPT-4 Turbo, GPT-3.5 Turbo** | OpenAI | Mais utilizado; 128K tokens; Vis√£o |
| **Claude 3.5 Sonnet, Claude 3 Opus** | Anthropic | Excelente racioc√≠nio; 200K tokens |
| **Gemini 2.0 Flash, Gemini 1.5 Pro** | Google | Multimodal; 1M tokens; An√°lise de v√≠deos |

---

### 3.3 Modelos de Embedding

| Modelo | Provedor | Caracter√≠sticas |
|--------|----------|----------------|
| **text-embedding-3-large** | OpenAI | Mais utilizado; 3072 dimens√µes; Qualidade superior |
| **text-embedding-3-small** | OpenAI | Vers√£o r√°pida; 1536 dimens√µes; Bom custo-benef√≠cio |
| **nomic-embed-text** | Nomic AI | Open-source; 768 dimens√µes; Alternativa gratuita |
| **bge-large-en-v1.5** | BAAI | Open-source; 1024 dimens√µes; Excelente performance |

---

### 3.4 Modelos de Reranking

| Modelo | Provedor | Caracter√≠sticas |
|--------|----------|----------------|
| **bge-reranker-large** | BAAI | Open-source; Melhora precis√£o em 20-40%; Roda localmente |
| **cross-encoder/ms-marco-MiniLM-L-12-v2** | Sentence Transformers | Open-source; R√°pido; Bom custo-benef√≠cio |

---

### 3.5 Modelos de C√≥digo

| Modelo | Provedor | Caracter√≠sticas |
|--------|----------|----------------|
| **CodeLlama** | Meta | Open-source; Especializado em c√≥digo; Roda localmente |
| **Deepseek-Coder** | DeepSeek | Open-source; Excelente em c√≥digo; Muito preciso |

---

### 3.6 Modelos Vision (VLM)

| Modelo | Provedor | Caracter√≠sticas |
|--------|----------|----------------|
| **GPT-4o Vision** | OpenAI | Mais utilizado; An√°lise de imagens; Extra√ß√£o de texto |
| **Claude Vision** | Anthropic | An√°lise detalhada; Extra√ß√£o de informa√ß√µes |
| **Gemini Vision** | Google | An√°lise de imagens; An√°lise de v√≠deos |
| **LLaVA** | Open-source | Open-source; Roda localmente; Alternativa gratuita |

---

### 3.7 Modelos Text-to-Image

| Modelo | Provedor | Caracter√≠sticas |
|--------|----------|----------------|
| **DALL-E 3** | OpenAI | Mais utilizado em produ√ß√£o; Qualidade alta |
| **Stable Diffusion 3** | Stability AI | Open-source; Roda localmente; Comunidade grande |
| **Midjourney** | Midjourney | Qualidade art√≠stica; Interface Discord |

---

### 3.8 Modelos ASR (Speech-to-Text)

| Modelo | Provedor | Caracter√≠sticas |
|--------|----------|----------------|
| **Whisper** | OpenAI | Open-source; Mais utilizado; M√∫ltiplos idiomas; Roda localmente |
| **Google Speech-to-Text** | Google | Muito utilizado em produ√ß√£o; M√∫ltiplos idiomas |

---

### 3.9 Modelos TTS (Text-to-Speech)

| Modelo | Provedor | Caracter√≠sticas |
|--------|----------|----------------|
| **OpenAI TTS** | OpenAI | Muito utilizado; M√∫ltiplas vozes; Lat√™ncia baixa |
| **ElevenLabs** | ElevenLabs | Vozes mais realistas; Muito usado em produ√ß√£o |
| **Bark** | Suno AI | Open-source; Roda localmente; Alternativa gratuita |

---

### 3.10 Vector Databases

| Banco | Tipo | Caracter√≠sticas |
|-------|------|----------------|
| **Pinecone** | SaaS | Mais utilizado em produ√ß√£o; Gerenciado; Escal√°vel |
| **Weaviate** | Open/SaaS | Open-source; Customiz√°vel; Suporte a m√∫ltiplos modelos |
| **Milvus** | Open-source | Open-source; Escal√°vel; Muito usado na √Åsia |
| **Qdrant** | Open/SaaS | Open-source; R√°pido; Filtros avan√ßados |
| **PostgreSQL + pgvector** | Open-source | Open-source; Integra√ß√£o com banco relacional; Custo baixo |

---

### 3.11 Bancos de Dados de Grafos

| Banco | Tipo | Caracter√≠sticas |
|-------|------|----------------|
| **Neo4j** | SaaS / Open | Mais utilizado para GraphRAG; Consultas poderosas |

---

### 3.12 Servi√ßos de Busca

| Servi√ßo | O que faz | Caracter√≠sticas |
|---------|-----------|----------------|
| **Perplexity API** | Busca com IA em tempo real | Busca em tempo real; Cita√ß√µes; Respostas estruturadas |
| **Tavily Search API** | Busca otimizada para agentes | Busca relevante; Integrada com LangChain |
| **Serper API** | Busca do Google para agentes | Busca Google; R√°pida; Confi√°vel |

---

### 3.13 Servi√ßos de Fine-tuning

| Servi√ßo | Provedor | Caracter√≠sticas |
|---------|----------|----------------|
| **OpenAI Fine-tuning API** | OpenAI | Mais utilizado; Simples; R√°pido |
| **Anthropic Fine-tuning** | Anthropic | Qualidade; Suporte; Customiza√ß√£o |

---

### 3.14 Plataformas de Observability

| Plataforma | O que faz | Caracter√≠sticas |
|------------|-----------|----------------|
| **LangSmith** | Rastreamento e debugging de LLMs | Rastreamento completo; Debugging; Otimiza√ß√£o |
| **Langfuse** | Observabilidade open-source para LLMs | Open-source; Rastreamento; Analytics |
| **Datadog** | Monitoramento e observabilidade | Monitoramento completo; Alertas; Integra√ß√£o |

---

### 3.15 Reposit√≥rios de Modelos

| Reposit√≥rio | O que oferece | Caracter√≠sticas |
|-------------|---------------|----------------|
| **Hugging Face Hub** | Reposit√≥rio de modelos open-source | 500K+ modelos; Datasets; Spaces; Comunidade |
| **OpenRouter** | Agregador de modelos | Acesso a m√∫ltiplos modelos via API unificada |

---

### 3.16 Servi√ßos de Model Serving

| Servi√ßo | O que faz | Caracter√≠sticas |
|---------|-----------|----------------|
| **Replicate** | Rodar modelos open-source via API | Sem gerenciar infraestrutura; Pre√ßo por uso |
| **Together AI** | Rodar modelos open-source | Modelos open-source; Pre√ßo competitivo |
| **Groq** | Hardware especializado para LLMs | Muito r√°pido; Lat√™ncia baixa |
| **Hugging Face Spaces** | Hospedar e compartilhar modelos | Hosting de modelos; Demos; Colabora√ß√£o; Gratuito |

---

## 4. Exemplos Pr√°ticos com Arquitetura

### Exemplo 1: RAG - Retrieval-Augmented Generation

**Caso de Uso:** Empresa tem 10.000 artigos de suporte e quer chatbot que responda com precis√£o.

**Problema:**
- LLM gen√©rico n√£o conhece produtos espec√≠ficos
- Respostas gen√©ricas e imprecisas
- Clientes ficam insatisfeitos

**Solu√ß√£o com RAG:**
```
1. Cliente pergunta: "Como resetar minha senha?"
2. Sistema busca na base de conhecimento
3. Encontra: "Artigo #234: Resetar senha em 3 passos"
4. LLM l√™ artigo + pergunta
5. Responde com instru√ß√µes precisas do seu produto
```

**Snippet de C√≥digo (Python + LangChain):**
```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

model = ChatOpenAI(model="gpt-4o")
vectorstore = FAISS.from_texts(
    ["Artigo #234: Para resetar a senha, acesse configura√ß√µes > seguran√ßa."], 
    embedding=OpenAIEmbeddings()
)
retriever = vectorstore.as_retriever()

template = "Responda com base no contexto: {context}\nPergunta: {question}"
prompt = ChatPromptTemplate.from_template(template)
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | model
)

print(chain.invoke("Como reseto a senha?").content)
```

**Arquitetura RAG:**
```mermaid
graph LR
    A["üìù Documentos<br/>(10.000 artigos)"] -->|Embedding| B["üî¢ Vector DB<br/>(Pinecone)"]
    C["üë§ Pergunta do<br/>Usu√°rio"] -->|Embedding| D["üîç Vector Search"]
    B -->|Busca Sem√¢ntica| D
    D -->|Top 3 Documentos| E["üß† LLM<br/>(GPT-4o)"]
    C -->|Contexto| E
    E -->|Resposta Precisa| F["üí¨ Resposta<br/>ao Usu√°rio"]
    
    style A fill:#e1f5ff
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
    style F fill:#f1f8e9
```

**Como usar:**
1. **Preparar documentos:** Coletar artigos, dividir em chunks de 500 tokens, gerar embeddings
2. **Indexar:** Usar Pinecone ou Weaviate, armazenar embeddings + metadados
3. **Buscar:** Converter pergunta em embedding, buscar top 3 documentos similares
4. **Melhorias:** Usar reranking (bge-reranker-large) e query rewriting

**Ferramentas:** LangChain/LlamaIndex, Pinecone/Weaviate, OpenAI API, LangSmith

**Benef√≠cio:** Respostas precisas, reduz alucina√ß√µes, conhecimento atualizado.

---

### Exemplo 2: Fine-tuning com LoRA

**Caso de Uso:** Cl√≠nica m√©dica quer modelo que classifique sintomas com precis√£o m√©dica.

**Problema:**
- GPT gen√©rico confunde sintomas
- Resposta: "Pode ser gripe ou COVID"
- N√£o √© confi√°vel para diagn√≥stico

**Solu√ß√£o com Fine-tuning:**
```
1. Coletar 5.000 exemplos de sintomas + diagn√≥sticos corretos
2. Treinar modelo com LoRA (eficiente)
3. Modelo aprende padr√µes espec√≠ficos
4. Resposta: "Baseado em seus sintomas, probabilidade 85% de bronquite viral"
```

**Snippet de C√≥digo (Python + Unsloth):**
```python
from unsloth import FastLanguageModel
from trl import SFTTrainer
from transformers import TrainingArguments

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "unsloth/llama-3-8b-bnb-4bit",
    max_seq_length = 2048,
    load_in_4bit = True,
)

model = FastLanguageModel.get_peft_model(
    model, r = 16, target_modules = ["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_alpha = 16, lora_dropout = 0,
    use_gradient_checkpointing = True,
)

trainer = SFTTrainer(
    model = model, tokenizer = tokenizer, train_dataset = dataset,
    dataset_text_field = "text", max_seq_length = 2048,
    args = TrainingArguments(
        per_device_train_batch_size = 2, gradient_accumulation_steps = 4,
        max_steps = 60, learning_rate = 2e-4,
        fp16 = not torch.cuda.is_bf16_supported(),
        bf16 = torch.cuda.is_bf16_supported(), output_dir = "outputs",
    ),
)

trainer.train()
```

**Arquitetura:**
```mermaid
graph LR
    A["üìä Dataset<br/>(5.000 exemplos)"] -->|Preparar| B["üîß Transformers Trainer<br/>ou Axolotl"]
    C["üß† Modelo Base<br/>(Llama 3.2)"] -->|Carregar| B
    B -->|LoRA Adapter<br/>2% par√¢metros| D["‚öôÔ∏è Fine-tuning<br/>(2-4 horas)"]
    D -->|Salvar| E["üíæ Modelo Fine-tuned<br/>(+ LoRA weights)"]
    E -->|Produ√ß√£o| F["üè• Classifica√ß√£o<br/>de Sintomas"]
    
    style A fill:#e1f5ff
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
    style F fill:#f1f8e9
```

**Como usar:**
1. **Preparar Dataset:** 5.000 exemplos (sintomas ‚Üí diagn√≥stico), formato JSONL
2. **Escolher Framework:** Transformers Trainer, Axolotl ou Unsloth
3. **Configurar LoRA:** Rank 8-16, reduzir par√¢metros em 99%
4. **Treinar:** 2-4 horas em GPU
5. **Deployar:** Usar vLLM ou TGI, lat√™ncia <100ms

**Ferramentas:** Transformers Trainer/Axolotl, Unsloth, TRL, RAGAS, vLLM

**Benef√≠cio:** Precis√£o especializada, confi√°vel para dom√≠nio espec√≠fico.

---

### Exemplo 3: Agentic RAG com LangGraph

**Caso de Uso:** Responder: *"Qual √© a pol√≠tica de devolu√ß√£o para clientes que compraram h√° mais de 30 dias?"*

**Problema:**
- RAG simples busca por "devolu√ß√£o"
- Retorna artigo gen√©rico
- N√£o responde a pergunta espec√≠fica

**Solu√ß√£o com Agentic RAG:**
```
1. Agente recebe pergunta
2. Pensa: "Preciso de 2 informa√ß√µes: pol√≠tica geral + regras especiais"
3. Executa 2 buscas diferentes
4. Sintetiza: "Pol√≠tica geral √© 30 dias, mas h√° exce√ß√£o se produto tiver defeito"
```

**Snippet de C√≥digo (Python + LangGraph):**
```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated

class AgentState(TypedDict):
    question: str
    context: str
    answer: str

def retrieve(state):
    return {"context": "Contexto recuperado"}

def generate(state):
    return {"answer": "Resposta gerada"}

workflow = StateGraph(AgentState)
workflow.add_node("retrieve", retrieve)
workflow.add_node("generate", generate)
workflow.set_entry_point("retrieve")
workflow.add_edge("retrieve", "generate")
workflow.add_edge("generate", END)

app = workflow.compile()
result = app.invoke({"question": "Minha pergunta"})
```

**Arquitetura:**
```mermaid
graph LR
    A["üë§ Pergunta<br/>Complexa"] -->|Receber| B["ü§ñ Agente<br/>(LangGraph)"]
    B -->|Planejar| C["üß† Racioc√≠nio<br/>do Agente"]
    C -->|Busca 1| D["üîç Pol√≠tica Geral<br/>de Devolu√ß√£o"]
    C -->|Busca 2| E["üîç Regras Especiais<br/>para Compras Antigas"]
    D -->|Resultado| F["üìä S√≠ntese<br/>de Informa√ß√µes"]
    E -->|Resultado| F
    F -->|Resposta Final| G["üí¨ Resposta<br/>Completa"]
    
    style A fill:#e1f5ff
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#e8f5e9
    style F fill:#fce4ec
    style G fill:#f1f8e9
```

**Ferramentas:** LangGraph, LangChain, Pinecone/Weaviate, LangSmith

**Benef√≠cio:** Respostas mais precisas, racioc√≠nio inteligente, menos alucina√ß√µes.

---

### Exemplo 4: Vibecoding com Cursor

**Caso de Uso:** Desenvolver aplica√ß√£o RAG em 1 dia (vs 1 semana manualmente).

**Problema:**
- Desenvolvimento manual √© lento
- Muitos erros de digita√ß√£o
- Debugging consome tempo

**Solu√ß√£o com Vibecoding:**
```
1. Abrir Cursor
2. Descrever: "Crie um chatbot RAG com LangChain"
3. Cursor gera c√≥digo automaticamente
4. Voc√™ revisa e ajusta
5. Pronto em horas, n√£o dias
```

**Arquitetura:**
```mermaid
graph LR
    A["üí° Ideia<br/>do Desenvolvedor"] -->|Descrever| B["ü§ñ Cursor<br/>(IDE com IA)"]
    B -->|Gerar| C["üìù C√≥digo<br/>Autom√°tico"]
    C -->|Revisar| D["üëÄ Desenvolvedor<br/>Revisa"]
    D -->|Ajustar| E["üîß Refinamento"]
    E -->|Testar| F["‚úÖ Aplica√ß√£o<br/>Pronta"]
    
    style A fill:#e1f5ff
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
    style F fill:#f1f8e9
```

**Ferramentas:** Cursor, GitHub Copilot, Claude API/OpenAI API

**Benef√≠cio:** Desenvolvimento 5-10x mais r√°pido, menos erros.

---

### Exemplo 5: No-Code com Dify

**Caso de Uso:** N√£o-t√©cnico quer criar chatbot RAG sem escrever c√≥digo.

**Problema:**
- N√£o sabe programar
- Precisa de solu√ß√£o r√°pida
- Or√ßamento limitado

**Solu√ß√£o com Dify:**
```
1. Abrir Dify
2. Criar novo "Application"
3. Arrastar blocos: Input ‚Üí RAG ‚Üí LLM ‚Üí Output
4. Conectar blocos
5. Publicar como API ou chatbot
6. Pronto! Sem uma linha de c√≥digo
```

**Arquitetura:**
```mermaid
graph LR
    A["üìù Documentos<br/>(Upload)"] -->|Indexar| B["üî¢ Vector DB<br/>(Integrado)"]
    C["üë§ Pergunta<br/>(Input Block)"] -->|Enviar| D["üîç RAG Block<br/>(Buscar)"]
    B -->|Resultados| D
    D -->|Documentos| E["üß† LLM Block<br/>(Processar)"]
    C -->|Contexto| E
    E -->|Resposta| F["üí¨ Output Block<br/>(Exibir)"]
    
    style A fill:#e1f5ff
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
    style F fill:#f1f8e9
```

**Ferramentas:** Dify, OpenAI API/Claude API

**Benef√≠cio:** N√£o-t√©cnicos constroem aplica√ß√µes complexas, desenvolvimento r√°pido.

---

### Exemplo 6: Monitoramento de Custos com Helicone

**Caso de Uso:** Empresa usa 10 APIs de LLM e quer rastrear gastos.

**Problema:**
- M√∫ltiplas APIs (OpenAI, Anthropic, Google)
- Dif√≠cil rastrear gastos
- Sem visibilidade de custos por aplica√ß√£o

**Solu√ß√£o com Helicone:**
```
1. Integrar Helicone em todas as APIs
2. Helicone intercepta requisi√ß√µes
3. Rastreia: tokens, custo, lat√™ncia, modelo
4. Dashboard mostra gastos em tempo real
5. Alertas quando gastos excedem limite
```

**Snippet de C√≥digo (Python + Helicone):**
```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-...",
    base_url="https://oai.hconeai.com/v1",
    default_headers={"Helicone-Auth": "Bearer sk-helicone-..."}
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Ol√°!"}],
    user="user-123"
)
```

**Arquitetura:**
```mermaid
graph LR
    A["üîó Aplica√ß√£o<br/>(LangChain)"] -->|Requisi√ß√£o| B["üîç Helicone<br/>(Proxy)"]
    B -->|Interceptar| C["üìä Rastreamento<br/>(Tokens, Custo)"]
    B -->|Encaminhar| D["üß† OpenAI API<br/>(ou outra)"]
    D -->|Resposta| B
    B -->|Retornar| A
    C -->|Armazenar| E["üìà Dashboard<br/>(Helicone)"]
    
    style A fill:#e1f5ff
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
```

**Ferramentas:** Helicone, OpenAI API/Anthropic API, LangChain

**Benef√≠cio:** Visibilidade de custos, otimiza√ß√£o de gastos, alertas autom√°ticos.

---

## 5. Seguran√ßa e Governan√ßa

### 5.1 Principais Vulnerabilidades (OWASP Top 10 LLM)

| Vulnerabilidade | Descri√ß√£o | Mitiga√ß√£o |
|----------------|-----------|-----------|
| **Prompt Injection** | Atacante manipula input para ignorar instru√ß√µes | Delimitadores claros; Valida√ß√£o de input; LLM Guardrails |
| **Insecure Output Handling** | Sa√≠da do LLM executada sem valida√ß√£o | Sandboxing; Tratamento de sa√≠da como n√£o confi√°vel |
| **Sensitive Data Exposure** | Modelo revela PII ou segredos | PII Redaction; Filtragem de sa√≠da |
| **Model Denial of Service** | Atacante sobrecarrega modelo | Rate limiting; Limites de tokens; Timeouts |

### 5.2 Ferramentas de Seguran√ßa

| Ferramenta | O que faz | Quando usar |
|------------|-----------|-------------|
| **NeMo Guardrails** | Adicionar regras de seguran√ßa em di√°logos | Bloquear t√≥picos sens√≠veis; Valida√ß√£o de fatos |
| **Lakera Guard** | Detec√ß√£o de Prompt Injection e Jailbreaks | Prote√ß√£o de endpoints p√∫blicos |
| **Microsoft Presidio** | Detec√ß√£o e anonimiza√ß√£o de PII | Mascarar dados sens√≠veis; Compliance (LGPD/GDPR) |
| **Garak** | Red teaming automatizado para LLMs | Testar vulnerabilidades; Scan de seguran√ßa |

---

## Estrutura

- 35+ Conceitos fundamentais
- Ferramentas por tipo (Frameworks, Bibliotecas, Engines, Plataformas, Fine-tuning)
- Recursos (Modelos, Vector Databases, Embeddings, Reranking)
- 6 Exemplos pr√°ticos com diagramas Mermaid
- Arquitetura visual para cada solu√ß√£o

**Exerc√≠cios:**
1. Identifique seu caso de uso principal
2. Escolha as ferramentas certas da tabela
3. Comece com prototipagem r√°pida (Dify, LangChain)
4. Escale com observabilidade (LangSmith, Langfuse)
5. Monitore custos (Helicone)

---

Otavio Lemos | otavieraspfc@gmail.com
